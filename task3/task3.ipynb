{"cells":[{"cell_type":"code","execution_count":5,"id":"20c5d195","metadata":{"id":"20c5d195"},"outputs":[{"name":"stderr","output_type":"stream","text":["<>:6: SyntaxWarning: invalid escape sequence '\\e'\n","<>:11: SyntaxWarning: invalid escape sequence '\\e'\n","<>:6: SyntaxWarning: invalid escape sequence '\\e'\n","<>:11: SyntaxWarning: invalid escape sequence '\\e'\n","C:\\Users\\Sakthibala\\AppData\\Local\\Temp\\ipykernel_20744\\1372074437.py:6: SyntaxWarning: invalid escape sequence '\\e'\n","  directory = 'enron1\\enron1\\spam'\n","C:\\Users\\Sakthibala\\AppData\\Local\\Temp\\ipykernel_20744\\1372074437.py:11: SyntaxWarning: invalid escape sequence '\\e'\n","  directory = 'enron1\\enron1\\ham'\n"]},{"name":"stdout","output_type":"stream","text":["skipped 0754.2004-04-01.GP.spam.txt\n","skipped 1414.2004-06-24.GP.spam.txt\n","skipped 2042.2004-08-30.GP.spam.txt\n","skipped 2140.2004-09-13.GP.spam.txt\n","skipped 2248.2004-09-23.GP.spam.txt\n","skipped 2526.2004-10-17.GP.spam.txt\n","skipped 2649.2004-10-27.GP.spam.txt\n","skipped 2698.2004-10-31.GP.spam.txt\n","skipped 3304.2004-12-26.GP.spam.txt\n","skipped 3364.2005-01-01.GP.spam.txt\n","skipped 4142.2005-03-31.GP.spam.txt\n","skipped 4201.2005-04-05.GP.spam.txt\n","skipped 4350.2005-04-23.GP.spam.txt\n","skipped 4566.2005-05-24.GP.spam.txt\n","skipped 5105.2005-08-31.GP.spam.txt\n"]}],"source":["import pandas as pd\n","import os\n","\n","def read_spam():\n","    category = 'spam'\n","    directory = 'enron1\\enron1\\spam'\n","    return read_category(category, directory)\n","\n","def read_ham():\n","    category = 'ham'\n","    directory = 'enron1\\enron1\\ham'\n","    return read_category(category, directory)\n","\n","def read_category(category, directory):\n","    emails = []\n","    for filename in os.listdir(directory):\n","        if not filename.endswith(\".txt\"):\n","            continue\n","        with open(os.path.join(directory, filename), 'r') as fp:\n","            try:\n","                content = fp.read()\n","                emails.append({'name': filename, 'content': content, 'category': category})\n","            except:\n","                print(f'skipped {filename}')\n","    return emails\n","\n","ham = read_ham()\n","spam = read_spam()\n","\n","df_ham = pd.DataFrame.from_records(ham)\n","df_spam = pd.DataFrame.from_records(spam)\n","\n","\n","df = pd.concat([df_ham, df_spam], ignore_index=True)\n"]},{"cell_type":"code","execution_count":6,"id":"c447c901","metadata":{"id":"c447c901"},"outputs":[],"source":["import re\n","\n","def preprocessor(e):\n","    e = re.sub('[^a-zA-Z]', ' ', e)\n","    return e.lower()\n","df['content'] = df['content'].apply(preprocessor)\n"]},{"cell_type":"markdown","id":"ba32521d","metadata":{"id":"ba32521d"},"source":["Step 3. We will now train the machine learning model. All the functions that you will need are imported for you. The instructions explain how the work and hint at which functions to use. You will likely need to refer to the scikit learn documentation to see how exactly to invoke the functions. It will be handy to keep that tab open."]},{"cell_type":"code","execution_count":7,"id":"1442d377","metadata":{"id":"1442d377"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9767441860465116\n","Confusion Matrix:\n","[[1058   23]\n"," [  13  454]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","         ham       0.99      0.98      0.98      1081\n","        spam       0.95      0.97      0.96       467\n","\n","    accuracy                           0.98      1548\n","   macro avg       0.97      0.98      0.97      1548\n","weighted avg       0.98      0.98      0.98      1548\n","\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","vectorizer = CountVectorizer(preprocessor=preprocessor)\n","\n","X_train, X_test, y_train, y_test = train_test_split(df['content'], df['category'], test_size=0.3, random_state=42)\n","\n","X_train_vec = vectorizer.fit_transform(X_train)\n","X_test_vec = vectorizer.transform(X_test)\n","\n","model = LogisticRegression()\n","model.fit(X_train_vec, y_train)\n","\n","y_pred = model.predict(X_test_vec)\n","\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"Confusion Matrix:\\n{conf_matrix}\")\n","print(f\"Classification Report:\\n{class_report}\")\n"]},{"cell_type":"markdown","id":"9674d032","metadata":{"id":"9674d032"},"source":["Step 4."]},{"cell_type":"code","execution_count":8,"id":"6b7d78c9","metadata":{"id":"6b7d78c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 10 spam words:\n","no: 1.005176874424519\n","http: 0.9617231391948734\n","prices: 0.7864730083916752\n","here: 0.7595177333997772\n","more: 0.7114563564000623\n","hello: 0.6832872351265962\n","off: 0.6792688361908978\n","rolex: 0.658806728771389\n","paliourg: 0.6464562411556374\n","removed: 0.6319666048781791\n","\n","Top 10 ham words:\n","attached: -1.4563094813428676\n","enron: -1.3984084856579755\n","thanks: -1.3198596174222768\n","daren: -1.1996589492546939\n","pictures: -1.1951347880027505\n","doc: -1.1858760845107634\n","deal: -1.1669655173851465\n","neon: -1.0905403084610414\n","xls: -1.0873520699384176\n","hpl: -1.0663621894270328\n"]}],"source":["feature_names = vectorizer.get_feature_names_out()\n","\n","importance = model.coef_[0]\n","\n","top_positive_indices = importance.argsort()[-10:][::-1]\n","top_negative_indices = importance.argsort()[:10]\n","\n","print(\"Top 10 spam words:\")\n","for i in top_positive_indices:\n","    print(f\"{feature_names[i]}: {importance[i]}\")\n","\n","print(\"\\nTop 10 ham words:\")\n","for i in top_negative_indices:\n","    print(f\"{feature_names[i]}: {importance[i]}\")\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"task3.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":5}
